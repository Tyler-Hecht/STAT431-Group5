---
title: "STAT431 Project - Revised"
author: "Chandler Nielsen"
date: "2023-04-16"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading Libraries

``` {r, message=FALSE, loadingLibraries}
library(tidyverse)
library(rjags)
library(readr)
```


## Cleaning Data

``` {r, warning=FALSE, CleaningForbayesianCategoricalOrdinal}

### Reading in Data - Cleaning SDP - Changing SentenceTime to numeric

filthyData2 <- read_csv("filthyData2.csv")
filthyData2 <- filthyData2[filthyData2$SentenceYears != "SDP", ]

sentenceYearVec <- ifelse(filthyData2$SentenceYears == "LIFE", 
                          Inf, 
                          as.numeric(filthyData2$SentenceYears))

sentenceMonthVec <- ifelse(is.na(filthyData2$SentenceMonths), 
                           0, 
                           as.numeric(filthyData2$SentenceMonths))

sentenceTimeVec <- sentenceYearVec + sentenceMonthVec / 12.0
filthyData2["SentenceTime"] <- sentenceTimeVec

###

### Selecting Desired Columns

cleanedFilthyData <- filthyData2 %>%
  select("Sex", "Race", "Veteran", "CrimeClass", "SentencingCounty", "SentenceTime", "DOB", "SentenceDate")

###

### Adding age to dataset

cleanedFilthyData["Age"] <- as.numeric((as.Date(strptime(cleanedFilthyData$SentenceDate, format = "%d-%b-%Y")) - as.Date(strptime(cleanedFilthyData$DOB, format = "%d-%b-%Y"))) / 365.0)
  
###

### Changing to Regions

regionVec = rep(0, length(cleanedFilthyData$SentencingCounty))
for (i in 1:length(cleanedFilthyData$SentencingCounty)) {
  
  if (cleanedFilthyData$SentencingCounty[i] == "Out of state") {
    regionVec[i] <- NA
    next
  }
  
  if (cleanedFilthyData$SentencingCounty[i] == 'Cook') {
    regionVec[i] <- 1
  }
  
  else if (cleanedFilthyData$SentencingCounty[i] %in% c("JoDaviess", "Stephenson", "Winnebago", 
                                                        "Boone", "McHenry", "Lake", "Carroll", 
                                                        "Ogle", "DeKalb", "Kane", "DuPage", 
                                                        "Whiteside", "Lee", "Kendall", 
                                                        "Grundy", "Will", "Kankakee")) {
    regionVec[i] <- 2
  }
  
  else if (cleanedFilthyData$SentencingCounty[i] %in% c("Rock Island", "Mercer", "Henry", 
                                                        "Bureau", "LaSalle", "Henderson", 
                                                        "Warren", "Knox", "Stark", "Putnam", 
                                                        "Marshall", "Livingston", "Ford", 
                                                        "Iroquois", "Vermillion", "Champaign", 
                                                        "McLean", "Woodford", "Tazewell", 
                                                        "Mason", "Peoria", "Fulton", "McDonough")) {
    regionVec[i] <- 3
  }
  
  else if (cleanedFilthyData$SentencingCounty[i] %in% c("Hancock", "Adams", "Schuyler", 
                                                        "Brown", "Cass", "Menard", "Logan", 
                                                        "Dewitt", "Piatt", "Douglas", "Edgar", 
                                                        "Clark", "Coles", "Cumberland", 
                                                        "Effingham", "Shelby", "Moultrie", 
                                                        "Macon", "Christian", "Montgomery", 
                                                        "Sangamon", "Morgan", "Macoupin", 
                                                        "Green", "Jersey", "Calhoun", "Scott", "Pike")) {
    regionVec[i] <- 4
  }
  
  else {
    regionVec[i] <- 5
  }                                                 
  
}

cleanedFilthyData["Region"] <- regionVec
 
###

### Changing Sex; Male = 1, Female = 2

cleanedFilthyDataSexVec <- ifelse(cleanedFilthyData$Sex == "Male", 1, 2)
cleanedFilthyData["SexNum"] <- cleanedFilthyDataSexVec

### Changing Race 

## Races Key
## 1 - Black
## 2 - White
## 3 - Hispanic
## 4 - Asian
## 5 - American Indian
## 6 - Biracial
## 7 - Unknown

myRaceVec <- rep(0, length(cleanedFilthyData$Race))
for(i in 1:length(cleanedFilthyData$Race)) {
  
  if (cleanedFilthyData$Race[i] == "Black") {
    myRaceVec[i] <- 1
  }
  
  else if (cleanedFilthyData$Race[i] == "White") {
    myRaceVec[i] <- 2
  }
  
  else if (cleanedFilthyData$Race[i] == "Hispanic") {
    myRaceVec[i] <- 3
  }
  
  else if (cleanedFilthyData$Race[i] == "Asian") {
    myRaceVec[i] <- 4
  }
  
  else if (cleanedFilthyData$Race[i] == "American Indian") {
    myRaceVec[i] <- 5
  }
  
  else if (cleanedFilthyData$Race[i] == "Bi-Racial") {
    myRaceVec[i] <- 6
  }
  
  else {
    myRaceVec[i] <- 7
  }
  
}

cleanedFilthyData["RaceNum"] <- myRaceVec

###

### Changing Crime Class

## Crime Class Key
## 1 - Murder
## 2 - Class X
## 3 - Class I
## 4 - Class II
## 5 - Class III
## 6 - Class IV
## 7 - Unclassified

myCrimeClassVec <- rep(0, length(cleanedFilthyData$CrimeClass))
for(i in 1:length(cleanedFilthyData$CrimeClass)) {
  
  if (cleanedFilthyData$CrimeClass[i] == "Murder") {
    myCrimeClassVec[i] <- 1
  }
  
  else if (cleanedFilthyData$CrimeClass[i] == "Class X") {
    myCrimeClassVec[i] <- 2
  }
  
  else if (cleanedFilthyData$CrimeClass[i] == "Class 1") {
    myCrimeClassVec[i] <- 3
  }
  
  else if (cleanedFilthyData$CrimeClass[i] == "Class 2") {
    myCrimeClassVec[i] <- 4
  }
  
  else if (cleanedFilthyData$CrimeClass[i] == "Class 3") {
    myCrimeClassVec[i] <- 5
  }
  
  else if (cleanedFilthyData$CrimeClass[i] == "Class 4") {
    myCrimeClassVec[i] <- 6
  }
  
  else {
    myCrimeClassVec[i] <- 7
  }
}

cleanedFilthyData["CrimeNum"] <- myCrimeClassVec

###

### Veteran Status; 1 - Veteran, 2 - Not Veteran, 3 - Unknown

veteranVec <- rep(0, length(cleanedFilthyData$Veteran))
for (i in 1:length(cleanedFilthyData$Veteran)) {
  
  if (cleanedFilthyData$Veteran[i] == "Yes") {
    veteranVec[i] <- 1
  }
  
  else if (cleanedFilthyData$Veteran[i] == "No") {
    veteranVec[i] <- 2
  }
  
  else {
    veteranVec[i] <- 3
  }
}

cleanedFilthyData["VetNum"] <- veteranVec

###

### Completed cleaning, Rearranging Columns

cleanedData <- cleanedFilthyData %>%
  select("VetNum", "RaceNum", "SexNum", "CrimeNum", "Region", "Age", "SentenceTime")

cleanedData <- cleanedData[!is.na(cleanedData$Region), ]

###

```

## Frequentist Analysis

``` {r frequentistNewClean}

withoutLife <- cleanedData[cleanedData$SentenceTime < Inf, ]

withoutLife$VetNum <- factor(withoutLife$VetNum)
withoutLife$RaceNum <- factor(withoutLife$RaceNum)
withoutLife$SexNum <- factor(withoutLife$SexNum)
withoutLife$CrimeNum <- factor(withoutLife$CrimeNum)
withoutLife$Region <- factor(withoutLife$Region)

myModel <- lm(SentenceTime ~ SexNum + RaceNum + VetNum + 
                CrimeNum + Region + Age, data = withoutLife)

summary(myModel)

```

## First Bayesian Model - LIFE removed

``` {r, eval=FALSE, bayesianModelMorePredictors}

initsSet1 <- list(list(a = 0,
                   Race = c(0, -0.6, -2.2, -2.4, 0.4, -2.2, -4.8),
                   CrimeType = c(0, -27.1, -35.4, -39.2, -41.4, -42.7, -44.1),
                   SexType = c(0, 2.9),
                   RegionType = c(0, -0.2, 1.4, -0.1, -0.04),
                   isVet = c(0, 0, 2),
                   ageCoef = 90),
              
              list(a = 5,
                   Race = c(0, -10, 10, -10, 10, -10, 10),
                   CrimeType = c(0, 17.5, 15, 0, -15, -17.5, -20),
                   SexType = c(0, 0),
                   RegionType = c(0, 1, -1, 1, -1),
                   isVet = c(0, 0, -5),
                   ageCoef = 50),
              
              list(a = 10,
                   Race = c(0, 10, -10, 10, -10, 10, -10),
                   CrimeType = c(0, -17.5, -15, 0, 15, 17.5, 20),
                   SexType = c(0, 10),
                   RegionType = c(0, -10, 10, -10, 10),
                   isVet = c(0, 10, 10),
                   ageCoef = 10))

cat('
model {
  for(i in 1:length(SentenceTime)) {
    SentenceTime[i] ~ dnorm(mu[i], tausq)
    mu[i] <- a + CrimeType[CrimeNum[i]] + SexType[SexNum[i]] + Race[RaceNum[i]] + RegionType[Region[i]] + isVet[VetNum[i]] + ageCoef * Age[i]
  }
  
  a ~ dnorm(0, 0.0001)
  tausq ~ dgamma(0.0001,0.0001)

  ageCoef ~ dnorm(0, 0.01)

  RegionType[1] ~ dnorm(0, 10000000)
  for (j in 2:5) {
    RegionType[j] ~ dnorm(0, 0.01)
  }
  
  SexType[1] ~ dnorm(0, 10000000)
  SexType[2] ~ dnorm(0, 0.01)
  
  Race[1] ~ dnorm(0, 10000000)
  for (l in 2:7) {
    Race[l] ~ dnorm(0, 0.01)
  }
  
  CrimeType[1] ~ dnorm(0, 10000000)
  for (w in 2:7) {
    CrimeType[w] ~ dnorm(0, 0.01)
  }
  
  isVet[1] ~ dnorm(0, 10000000)
  for (d in 2:3) {
    isVet[d] ~ dnorm(0, 0.01)
  }
  
}
', file = {revisedBayes1 = tempfile()})

revisedBayes1 <- jags.model(revisedBayes1, withoutLife, initsSet1, n.chains=3)
revised1sample1 <- coda.samples(revisedBayes1, 
                                c("a", "CrimeType", "SexType", "Race", "RegionType", "isVet", "ageCoef"), 
                                n.iter=2000)

gelman.plot(revised1sample1, autoburnin=FALSE)
gelman.diag(revised1sample1, autoburnin=FALSE)

summary(window(revised1sample1, 1800, 2000))

```
## To Analyze:
### Posterior Probabilities
### Regional differences?
### Convergence Concerns?
### Interpretation of Results?
### DIC?


## Multivariate Normal Bayesian Model

``` {r multivariateNormal}

Xmat<-model.matrix(myModel)
XtX<-t(Xmat)%*%Xmat
sig2hat<-summary(myModel)$sigma^2
p<- ncol(Xmat)-1

d <- list(y = withoutLife$SentenceTime,
          X = Xmat[,-1],
          B0 = rep(0,p),
          Sig0 = XtX[-1,-1],
          nu0 =1,
          sig20=sig2hat
          )

initsSet2 <- list(list(tausq=1, alpha = 1, beta=rnorm(p) ),
                  list(tausq=1, alpha=-1, beta=rnorm(p,sd=3) ),
                  list(tausq=1, alpha=0, beta=rnorm(p,sd=.5) )
                  )

cat('

data {
  dim.X <- dim(X)
  n <- dim.X[1]
}

model {

  for(i in 1:n) {
    y[i] ~ dnorm(mu[i], tausq)
    mu[i] <- alpha + X[i,]%*%beta[]
  }
  tausq ~ dgamma(nu0/2,nu0*sig20/2)
  sigma2 <- 1/tausq

  alpha ~ dnorm(0,.0001)
  beta ~ dmnorm(B0,ginv*tausq*Sig0)
  ginv ~ dgamma(.5,n/2)
  
  nativeSentenceInc <- beta[5] > 0
  
}
', file = {revisedBayes3 = tempfile()})

revisedBayesModel3 <- jags.model(revisedBayes3, d, initsSet2, n.chains=3)


revised3sample1 <- coda.samples(revisedBayesModel3, 
                                c("nativeSentenceInc"), 
                                n.iter=3000)



# gelman.plot(revised3sample1, autoburnin=FALSE)
# gelman.diag(revised3sample1, autoburnin=FALSE)

summary(window(revised3sample1, 2800, 3000))


```


























































































## Stochastic Search Variable Selection for Multivariate Normal Model

``` {r SSVS}

Xmat<-model.matrix(myModel)
XtX<-t(Xmat)%*%Xmat
sig2hat<-summary(myModel)$sigma^2
p<- ncol(Xmat)-1

d <- list(y = withoutLife$SentenceTime,
          X = Xmat[,-1]
          )

initsSetSSVS <- list(list(tausq=1, gamma = rep(1, p), alpha = 1),
                  list(tausq=1, gamma = rep(0, p), alpha=-1),
                  list(tausq=1, gamma = rep(1, p), alpha=0)
                  )

cat('

data {
  dim.X <- dim(X)
  n <- dim.X[1]
  p <- dim.X[2]
}

model {

  for (i in 1:n) {
    y[i] ~ dnorm(mu[i], tausq)
    mu[i] <- alpha + X[i,] %*% beta[]
  }
  
  for (j in 1:p) {
    beta[j] <- gamma[j]*delta[j]
    gamma[j] ~ dbern(0.5)
    delta[j] ~ dnorm(0, tausq)
  
  }

  alpha ~ dnorm(0, 0.01)
  tausq ~ dgamma(0.1, 0.1)
  sigma2 <- 1/tausq
  
}
', file = {revisedBayesSSVS = tempfile()})

revisedBayesModelSSVS <- jags.model(revisedBayesSSVS, d, initsSetSSVS, n.chains=3)
revisedSSVSsample1 <- coda.samples(revisedBayesModelSSVS, 
                                c("alpha", "beta", "gamma"), 
                                n.iter=2000)


summary(window(revisedSSVSsample1, 1800, 2000))



```


## Reduced Normal Model

### Including regressors 1, 3, 7, 10, 11, 12, 13, 14, 15, 17

``` {r multivariateNormal}

withoutLifeReduced <- cleanedData[cleanedData$SentenceTime < Inf, ]

withoutLifeReduced["region3orNot"] <- ifelse(withoutLifeReduced$Region == 3, 1, 0)

raceNumreduced <- rep(0, length(withoutLifeReduced$RaceNum))
for (i in 1:length(withoutLifeReduced$RaceNum)) {
  
  if (withoutLifeReduced$RaceNum[i] == 1) {
    raceNumreduced[i] <- 1
  }
  
  else if (withoutLifeReduced$RaceNum[i] == 3) {
    raceNumreduced[i] <- 2
  }
  
  else if (withoutLifeReduced$RaceNum[i] == 7) {
    raceNumreduced[i] <- 3
  }
  
  else {
    raceNumreduced[i] <- 0
  }
}

withoutLifeReduced["raceReduced"] <- raceNumreduced

withoutLifeReduced$raceReduced <- factor(withoutLifeReduced$raceReduced)
withoutLifeReduced$SexNum <- factor(withoutLifeReduced$SexNum)
withoutLifeReduced$CrimeNum <- factor(withoutLifeReduced$CrimeNum)
withoutLifeReduced$region3orNot <- factor(withoutLifeReduced$region3orNot)

myModelreduced <- lm(SentenceTime ~ SexNum + raceReduced + 
                CrimeNum + region3orNot, data = withoutLifeReduced)

Xmat<-model.matrix(myModelreduced)
XtX<-t(Xmat)%*%Xmat
sig2hat<-summary(myModelreduced)$sigma^2
p<- ncol(Xmat)-1

d <- list(y = withoutLifeReduced$SentenceTime,
          X = Xmat[,-1],
          B0 = rep(0,p),
          Sig0 = XtX[-1,-1],
          nu0 =1,
          sig20=sig2hat
          )

initsSetLast <- list(list(tausq=1, alpha = 1, beta=rnorm(p) ),
                  list(tausq=1, alpha=-1, beta=rnorm(p,sd=3) ),
                  list(tausq=1, alpha=0, beta=rnorm(p,sd=.5) )
                  )

cat('

data {
  dim.X <- dim(X)
  n <- dim.X[1]
}

model {

  for(i in 1:n) {
    y[i] ~ dnorm(mu[i], tausq)
    mu[i] <- alpha + X[i,]%*%beta[]
  }
  tausq ~ dgamma(nu0/2,nu0*sig20/2)
  sigma2 <- 1/tausq

  alpha ~ dnorm(0,.0001)
  beta ~ dmnorm(B0,ginv*tausq*Sig0)
  ginv ~ dgamma(.5,n/2)
  
}
', file = {revisedBayesLast = tempfile()})

revisedBayesModelLast <- jags.model(revisedBayesLast, d, initsSetLast, n.chains=3)

update(revisedBayesModelLast, 2000)
dic.samples(revisedBayesModelLast, 1000, type="pD")



# revised3sample1 <- coda.samples(revisedBayesModel3, 
#                                c("alpha"), 
#                                n.iter=3000)



# gelman.plot(revised3sample1, autoburnin=FALSE)
# gelman.diag(revised3sample1, autoburnin=FALSE)

# summary(window(revised3sample1, 2800, 3000))


```

## Junk Ideas and Models


### Poisson Regression Model

``` {r PoissonRegressionModel}

initsSet2 <- list(list(Race = c(0, -0.6, -2.2, -2.4, 0.4, -2.2, -4.8),
                   CrimeType = c(0, -27.1, -35.4, -39.2, -41.4, -42.7, -44.1),
                   SexType = c(0, 2.9),
                   RegionType = c(0, -0.2, 1.4, -0.1, -0.04),
                   isVet = c(0, 0, 2),
                   Age = 5),
              
              list(Race = c(10, -10, 10, -10, 10, -10, 10),
                   CrimeType = c(20, 17.5, 15, 0, -15, -17.5, -20),
                   SexType = c(2.9, 0),
                   RegionType = c(-1, 1, -1, 1, -1),
                   isVet = c(0, 0, 2),
                   Age = 30),
              
              list(Race = c(-10, 10, -10, 10, -10, 10, -10),
                   CrimeType = c(-20, -17.5, -15, 0, 15, 17.5, 20),
                   SexType = c(-10, 10),
                   RegionType = c(10, -10, 10, -10, 10),
                   isVet = c(0, 0, 2),
                   Age = 75))

roundedVec <- round(withoutLife$SentenceTime)
withoutLifePois <- withoutLife
withoutLifePois["SentenceTime"] <- roundedVec

cat('
model {
  for(i in 1:length(SentenceTime)) {
    SentenceTime[i] ~ dpois(lambda[i])
    log(lambda[i]) <- CrimeType[CrimeNum[i]] + SexType[SexNum[i]] + Race[RaceNum[i]] + RegionType[Region[i]] + isVet[VetNum[i]]
  }
  
  for (j in 1:5) {
    RegionType[j] ~ dnorm(0, 0.01)
  }
  
  for (k in 1:2) {
    SexType[k] ~ dnorm(0, 0.01)
  }
  
  for (l in 1:7) {
    Race[l] ~ dnorm(0, 0.01)
  }
  
  for (w in 1:7) {
    CrimeType[w] ~ dnorm(0, 0.01)
  }
  
  for (d in 1:3) {
    isVet[d] ~ dnorm(0, 0.01)
  }
  
}
', file = {revisedBayes2 = tempfile()})

revisedBayes2 <- jags.model(revisedBayes2, withoutLifePois, initsSet2, n.chains=3)
revised2sample1 <- coda.samples(revisedBayes2, 
                                c("CrimeType", "SexType", "Race", "RegionType", "isVet"), 
                                n.iter=4000)

gelman.plot(revised2sample1, autoburnin=FALSE)
gelman.diag(revised2sample1, autoburnin=FALSE)

summary(window(revised2sample1, 3500, 4000))

```

## To Analyze:
### Problems with Convergence?
### DIC comparison with most basic model?
### Posterior probabilities?
### Interpretation of results?
